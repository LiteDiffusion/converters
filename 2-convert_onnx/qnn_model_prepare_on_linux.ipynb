{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "5a8bae8a",
   "metadata": {},
   "source": [
    "The Qualcomm AI Engine Direct SDK allows clients to run ML models on HTP hardware. The following steps describe how to prepare and execute the Stable Diffusion models on Linux platforms with HTP capability.\n",
    "\n",
    "This document uses the term Qualcomm Neural Network (QNN) and Qualcomm AI Engine Direct SDK interchangeably.\n",
    "\n",
    "\n",
    "# Prerequisites\n",
    "\n",
    "1. Qualcomm AI Engine Direct SDK (with Ubuntu Linux support)\n",
    "2. Ubuntu 20.04 installation with required packages for QNN Tools\n",
    "3. Android Platform tools version 31 or greater\n",
    "4. This notebook could be executed with Anaconda (with the supplied environment.yaml) or a virtual environment(venv)\n",
    "5. Stable diffusion `.onnx` files and their corresponding AIMET encodings (generated via AIMET workflow)\n",
    "\n",
    "This work flow assumes that you have generated the Stable Diffusion model artifacts following the AIMET Stable Diffusion workflow:\n",
    "\n",
    "- Stable Diffusion text encoder model and its AIMET encodings\n",
    "- Stable Diffusion U-Net model and its AIMET encodings\n",
    "- Stable Diffusion Variational Auto Encoder (VAE) model and its AIMET encodings\n",
    "- `fp32.npy` file - a numpy object array saved as a Python pickle that contains data that is required as part of the model conversion step. \n",
    "\n",
    "\n",
    "# Tested Environment\n",
    "\n",
    "**Linux x86 PC**\n",
    "\n",
    "- Distributor ID: Ubuntu\n",
    "- Description:    Ubuntu 20.04.5 LTS\n",
    "- Release:        20.04\n",
    "- Platform: x86_64 AMD\n",
    "\n",
    "\n",
    "\n",
    "# Workflow\n",
    "\n",
    "\n",
    "The three models and encodings are processed independently via different executable QNN utilities available in the Qualcomm AI Engine Direct SDK.\n",
    "\n",
    "To prepare Stable Diffusion models for inference, the QNN executable utilities require an Ubuntu 20.04 environment\n",
    "\n",
    "1. Convert the `.onnx` files to their equivalent QNN representation with `A16W8` (16-bit activation and 8-bit weights)\n",
    "2. Generate the QNN model libraries\n",
    "3. Generate the QNN context binaries for the QNN HTP backend\n",
    "\n",
    "After preparing the Stable Diffusion models for inference, the next step is to execute the QNN context binaries for inference on a Snapdragon Android device. See qnn_model_execution_on_android.ipynb.\n",
    "\n",
    "\n",
    "![QNN Work flow](./jupyter_notebook_assets/qnn-workflow.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8d65266a",
   "metadata": {},
   "source": [
    "The Python environment can be set up using either Anaconda or Python virtual environment (venv).\n",
    "\n",
    "**Note:** One of the following two steps to setup the Python environment must be executed before executing the notebook.\n",
    "\n",
    "If you have already started the jupyer notebook, configure the Python environment before you continue. After configuring the Python environment, restart the notebook server and select the correct kernel."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6218fa25",
   "metadata": {},
   "source": [
    "# Setup\n",
    "\n",
    "### Set up Anaconda in an Ubuntu 20.04 terminal\n",
    "\n",
    "1. Install Anaconda from : https://repo.anaconda.com/archive/Anaconda3-2023.03-1-Linux-x86_64.sh.\n",
    "\n",
    "2. Execute the setup script with the following command.\n",
    "\n",
    "    `chmod a+x Anaconda3-2023.03-1-Linux-x86_64.sh && bash Anaconda3-2023.03-1-Linux-x86_64.sh`\n",
    "\n",
    "3. Configure an Anaconda environment with the following commands in the Ubuntu 20.04 terminal.\n",
    "\n",
    "    `conda create --name stable_diffusion_env python=3.8`\n",
    "    \n",
    "    `conda activate stable_diffusion_env`\n",
    "    \n",
    "    `conda install ipykernel` \n",
    "    \n",
    "    `ipython kernel install --user --name=stable_diffusion_env` \n",
    "\n",
    "### Setup venv (non-Anaconda) in an Ubuntu 20.04 terminal\n",
    "\n",
    "The following steps install the packages required to use the QNN tools in an Ubuntu 20.04 environment (Ubuntu terminal window).\n",
    "\n",
    "1. Update the package index files.\n",
    "\n",
    "    `sudo apt-get update`\n",
    "\n",
    "2. Install Python3.8 and necessary packages.\n",
    "\n",
    "    By default Ubuntu 20.04 should come with Python 3.8 and you don't need to install it again. However to reinstall it run the following command.\n",
    "\n",
    "    `sudo bash -c 'apt-get update && apt-get install software-properties-common && add-apt-repository ppa:deadsnakes/ppa && apt-get install python3.8 python3.8-distutils libpython3.8'`\n",
    "\n",
    "3. Install python3-pip.\n",
    "\n",
    "    `sudo apt-get install python3-pip`\n",
    "\n",
    "4. Install python3 virtual environnment support.\n",
    "\n",
    "    `sudo apt install python3-virtualenv`\n",
    "\n",
    "5. Create and activate a Python 3.8 virtual environment by executing the following commands.\n",
    "    ```\n",
    "    virtualenv -p /usr/bin/python3.8 venv_stable_diffusion\n",
    "    source venv_stable_diffusion/bin/activate\n",
    "    ```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "51d7d4f0",
   "metadata": {},
   "source": [
    "### Install the required python packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8f886b2a",
   "metadata": {},
   "outputs": [],
   "source": [
    "pip install --quiet -r requirements.txt"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "74c6106d",
   "metadata": {},
   "source": [
    "## Set up the Qualcomm AI Engine Direct SDK\n",
    "\n",
    "The following steps configure the Qualcomm AI Engine Direct SDK, which enables running Stable Diffusion on the device. \n",
    "Execute the following on an Ubuntu 20.04 terminal. \n",
    "\n",
    "**NOTE:** These steps require sudo or root privileges.\n",
    "\n",
    "1. After setting up Python and pip in Ubuntu, check QNN tool dependencies; see <QNN_SDK>/docs/QNN/general/setup.html for more information about QNN setup and the ML framework dependencies. \n",
    "2. Set the `QNN_SDK_ROOT` environment variable to the location of the Qualcomm AI Engine Directory. For **Linux**, `export QNN_SDK_ROOT=\"./assets/qnn_assets/unzipped_qnn_sdk_linux/\"`\n",
    "3. Check and install Linux dependencies.\n",
    "\n",
    "    ```\n",
    "    source $QNN_SDK_ROOT/bin/check-linux-dependency.sh\n",
    "    sudo apt-get install -y libtinfo5\n",
    "    ```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8b19b231",
   "metadata": {},
   "source": [
    "## Set up Python dependencies for the Qualcomm AI Engine"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7792a43a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "#Check and install Python dependencies\n",
    "QNN_SDK_ROOT=\"/opt/qcom/aistack/qairt/2.21.0.240401/\"\n",
    "!python $QNN_SDK_ROOT/bin/check-python-dependency"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "115b5a4c",
   "metadata": {},
   "source": [
    "# Prepare Stable Diffusion Models for Inference\n",
    "\n",
    "The following section uses the Qualcomm AI Engine Direct SDK to prepare stable diffusion models for on-target inference."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ed9eea2d",
   "metadata": {
    "vscode": {
     "languageId": "shellscript"
    }
   },
   "outputs": [],
   "source": [
    "# Set up environment variable to reference STABLE_DIFFUSION_MODELS\n",
    "STABLE_DIFFUSION_MODELS = os.path.join(os.getcwd(), \"../landscapePhotoreal_v1/\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cd5cb4cc",
   "metadata": {},
   "source": [
    "## Convert the model from ONNX representation to QNN representation\n",
    "\n",
    "The Qualcomm AI Engine Direct SDK `qnn-onnx-conerter` tool converts a model from ONNX representation to its equivalent QNN representation in `A16W8` precision. The encoding files generated from the AIMET workflow are provided as an input to this step via the `â€“quantization_overrides model.encodings` option.\n",
    "\n",
    "This step generates a `.cpp` file that represents the model as a series of QNN API calls and a `.bin` file that contains static data that is typically model weights and referenced by the `.cpp` file.\n",
    "\n",
    "This step must be done independently for all three models."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fc16ea5d",
   "metadata": {},
   "source": [
    "### Generate model inputs list/data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dd8c143b",
   "metadata": {},
   "outputs": [],
   "source": [
    "inputs_pickle_path=STABLE_DIFFUSION_MODELS + '/fp32.npy'\n",
    "!python3 generate_inputs.py --pickle_path $inputs_pickle_path --working_dir $STABLE_DIFFUSION_MODELS"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "22b1a5ea",
   "metadata": {},
   "source": [
    "### Set up environment variables for the Qualcomm AI Direct SDK tools"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "93c40d66",
   "metadata": {},
   "outputs": [],
   "source": [
    "env = os.environ.copy()\n",
    "env[\"QNN_SDK_ROOT\"] = QNN_SDK_ROOT\n",
    "env[\"PYTHONPATH\"] = QNN_SDK_ROOT + \"/benchmarks/QNN/:\" + QNN_SDK_ROOT + \"/lib/python\"\n",
    "env[\"PATH\"] = QNN_SDK_ROOT + \"/bin/x86_64-linux-clang:\" + env[\"PATH\"]\n",
    "env[\"LD_LIBRARY_PATH\"] = QNN_SDK_ROOT + \"/lib/x86_64-linux-clang:\" + os.environ['CONDA_PREFIX'] + \"/lib\"\n",
    "env[\"HEXAGON_TOOLS_DIR\"] = QNN_SDK_ROOT + \"/bin/x86_64-linux-clang\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d892476b",
   "metadata": {},
   "source": [
    "### Convert the text encoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c16c0206",
   "metadata": {
    "vscode": {
     "languageId": "shellscript"
    }
   },
   "outputs": [],
   "source": [
    "import subprocess\n",
    "\n",
    "!mkdir -p $STABLE_DIFFUSION_MODELS/converted_text_encoder\n",
    "proc = subprocess.Popen([QNN_SDK_ROOT + \"/bin/x86_64-linux-clang/qnn-onnx-converter\",\n",
    "                  \"-o\", STABLE_DIFFUSION_MODELS + \"/converted_text_encoder/qnn_model.cpp\",\n",
    "                   \"-i\",STABLE_DIFFUSION_MODELS + \"/text_encoder_onnx/text_encoder.onnx\",\n",
    "                   \"--input_list\", STABLE_DIFFUSION_MODELS + \"/text_encoder_onnx/text_encoder_input_list.txt\",\n",
    "                   \"--act_bw\", \"16\",\n",
    "                   \"--bias_bw\", \"32\",\n",
    "                   \"--quantization_overrides\", STABLE_DIFFUSION_MODELS + \"/text_encoder_onnx/text_encoder.encodings\"\n",
    "                 ],stdout=subprocess.PIPE, stderr=subprocess.PIPE,env=env)\n",
    "output, error = proc.communicate()\n",
    "print(output.decode(),error.decode())\n",
    "\n",
    "# Rename the model files to make them unique and helpful for subsequent stages\n",
    "!mv $STABLE_DIFFUSION_MODELS/converted_text_encoder/qnn_model.cpp $STABLE_DIFFUSION_MODELS/converted_text_encoder/text_encoder.cpp\n",
    "!mv $STABLE_DIFFUSION_MODELS/converted_text_encoder/qnn_model.bin $STABLE_DIFFUSION_MODELS/converted_text_encoder/text_encoder.bin\n",
    "!mv $STABLE_DIFFUSION_MODELS/converted_text_encoder/qnn_model_net.json $STABLE_DIFFUSION_MODELS/converted_text_encoder/text_encoder_net.json"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "95ab803d",
   "metadata": {},
   "source": [
    "### Convert U-Net\n",
    "Expected execution time: ~ 1.5 hours"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2ec70d7e",
   "metadata": {
    "vscode": {
     "languageId": "shellscript"
    }
   },
   "outputs": [],
   "source": [
    "!mkdir -p $STABLE_DIFFUSION_MODELS/converted_unet\n",
    "\n",
    "proc = subprocess.Popen([QNN_SDK_ROOT + \"/bin/x86_64-linux-clang/qnn-onnx-converter\",\n",
    "                  \"-o\", STABLE_DIFFUSION_MODELS + \"/converted_unet/qnn_model.cpp\",\n",
    "                   \"-i\",STABLE_DIFFUSION_MODELS + \"/unet_onnx/unet.onnx\",\n",
    "                   \"--input_list\", STABLE_DIFFUSION_MODELS + \"/unet_onnx/unet_input_list.txt\",\n",
    "                   \"--act_bw\", \"16\",\n",
    "                   \"--bias_bw\", \"32\",\n",
    "                   \"--quantization_overrides\", STABLE_DIFFUSION_MODELS + \"/unet_onnx/unet.encodings\",\n",
    "                   \"-l\", \"input_3\", \"NONTRIVIAL\"\n",
    "                 ],stdout=subprocess.PIPE, stderr=subprocess.PIPE,env=env)\n",
    "output, error = proc.communicate()\n",
    "print(output.decode(),error.decode())\n",
    "\n",
    "# Rename the model files to make them unique and helpful for subsequent stages\n",
    "!mv $STABLE_DIFFUSION_MODELS/converted_unet/qnn_model.cpp $STABLE_DIFFUSION_MODELS/converted_unet/unet.cpp\n",
    "!mv $STABLE_DIFFUSION_MODELS/converted_unet/qnn_model.bin $STABLE_DIFFUSION_MODELS/converted_unet/unet.bin\n",
    "!mv $STABLE_DIFFUSION_MODELS/converted_unet/qnn_model_net.json $STABLE_DIFFUSION_MODELS/converted_unet/unet_net.json"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "217321c0",
   "metadata": {},
   "source": [
    "### Convert the VAE decoder\n",
    "Expected execution time: ~25 minutes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9a529446",
   "metadata": {
    "vscode": {
     "languageId": "shellscript"
    }
   },
   "outputs": [],
   "source": [
    "!mkdir -p $STABLE_DIFFUSION_MODELS/converted_vae_decoder\n",
    "\n",
    "proc = subprocess.Popen([QNN_SDK_ROOT + \"/bin/x86_64-linux-clang/qnn-onnx-converter\",\n",
    "                  \"-o\", STABLE_DIFFUSION_MODELS + \"/converted_vae_decoder/qnn_model.cpp\",\n",
    "                   \"-i\",STABLE_DIFFUSION_MODELS + \"/vae_decoder_onnx/vae_decoder.onnx\",\n",
    "                   \"--input_list\", STABLE_DIFFUSION_MODELS + \"/vae_decoder_onnx/vae_decoder_input_list.txt\",\n",
    "                   \"--act_bw\", \"16\",\n",
    "                   \"--bias_bw\", \"32\",\n",
    "                   \"--quantization_overrides\", STABLE_DIFFUSION_MODELS + \"/vae_decoder_onnx/vae_decoder.encodings\"\n",
    "                 ],stdout=subprocess.PIPE, stderr=subprocess.PIPE,env=env)\n",
    "output, error = proc.communicate()\n",
    "print(output.decode(),error.decode())\n",
    "\n",
    "\n",
    "# Rename for uniqueness\n",
    "!mv $STABLE_DIFFUSION_MODELS/converted_vae_decoder/qnn_model.cpp $STABLE_DIFFUSION_MODELS/converted_vae_decoder/vae_decoder.cpp\n",
    "!mv $STABLE_DIFFUSION_MODELS/converted_vae_decoder/qnn_model.bin $STABLE_DIFFUSION_MODELS/converted_vae_decoder/vae_decoder.bin\n",
    "!mv $STABLE_DIFFUSION_MODELS/converted_vae_decoder/qnn_model_net.json $STABLE_DIFFUSION_MODELS/converted_vae_decoder/vae_decoder_net.json"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a2cfc5ab",
   "metadata": {},
   "source": [
    "## QNN model library\n",
    "\n",
    "The  Qualcomm AI Engine Direct SDK `qnn-model-lib-generator` compiles the model `.cpp` and `.bin` files into a shared object library for a specific target. This example generates a shared object library for x86_64-linux target.\n",
    "\n",
    "The inputs to this stage are the `model.cpp` and `model.bin` files generated in the previous step.\n",
    "\n",
    "### Generate the text encoder model library"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "85264fb5",
   "metadata": {
    "vscode": {
     "languageId": "shellscript"
    }
   },
   "outputs": [],
   "source": [
    "proc = subprocess.Popen([QNN_SDK_ROOT + \"/bin/x86_64-linux-clang/qnn-model-lib-generator\",\n",
    "                        \"-c\", STABLE_DIFFUSION_MODELS + \"/converted_text_encoder/text_encoder.cpp\",\n",
    "                        \"-b\", STABLE_DIFFUSION_MODELS + \"/converted_text_encoder/text_encoder.bin\",\n",
    "                        \"-t\", \"x86_64-linux-clang\",\n",
    "                        \"-o\", STABLE_DIFFUSION_MODELS + \"/converted_text_encoder\"\n",
    "                        ],stdout=subprocess.PIPE, stderr=subprocess.PIPE,env=env)\n",
    "output, error = proc.communicate()\n",
    "print(output.decode(),error.decode())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "516bcd77",
   "metadata": {},
   "source": [
    "### Generate the U-Net model library\n",
    "Expected execution time: ~25 minutes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "99dce655",
   "metadata": {
    "vscode": {
     "languageId": "shellscript"
    }
   },
   "outputs": [],
   "source": [
    "proc = subprocess.Popen([QNN_SDK_ROOT + \"/bin/x86_64-linux-clang/qnn-model-lib-generator\",\n",
    "                        \"-c\", STABLE_DIFFUSION_MODELS + \"/converted_unet/unet.cpp\",\n",
    "                        \"-b\", STABLE_DIFFUSION_MODELS + \"/converted_unet/unet.bin\",\n",
    "                        \"-t\", \"x86_64-linux-clang\",\n",
    "                        \"-o\", STABLE_DIFFUSION_MODELS + \"/converted_unet\"\n",
    "                        ],stdout=subprocess.PIPE, stderr=subprocess.PIPE,env=env)\n",
    "output, error = proc.communicate()\n",
    "print(output.decode(),error.decode())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "08555911",
   "metadata": {},
   "source": [
    "### Generate the VAE decoder model library"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "15bc5a67",
   "metadata": {
    "vscode": {
     "languageId": "shellscript"
    }
   },
   "outputs": [],
   "source": [
    "proc = subprocess.Popen([QNN_SDK_ROOT + \"/bin/x86_64-linux-clang/qnn-model-lib-generator\",\n",
    "                        \"-c\", STABLE_DIFFUSION_MODELS + \"/converted_vae_decoder/vae_decoder.cpp\",\n",
    "                        \"-b\", STABLE_DIFFUSION_MODELS + \"/converted_vae_decoder/vae_decoder.bin\",\n",
    "                        \"-t\", \"x86_64-linux-clang\",\n",
    "                        \"-o\", STABLE_DIFFUSION_MODELS + \"/converted_vae_decoder\"\n",
    "                        ],stdout=subprocess.PIPE, stderr=subprocess.PIPE,env=env)\n",
    "output, error = proc.communicate()\n",
    "print(output.decode(),error.decode())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b11140c1",
   "metadata": {},
   "source": [
    "## QNN HTP context binary\n",
    "\n",
    "The  Qualcomm AI Engine Direct SDK `qnn-context-binary-generator` tool creates a QNN context binary applicable to the QNN HTP backend. This binary can be deployed to run on a Snapdragon Gen2 device the runs Android. This step requires the model shared object library from the previous step and the `libQnnHtp.so` library, available in the Qualcomm AI Engine Direct SDK.\n",
    "\n",
    "Provie additional options that pertain to the QNN HTP backend by passing the `libQnnHtpBackendExtensions.so` library that implements extensions for the QNN HTP backend. The library is available in the Qualcomm AI Engine Direct SDK. The library and configurations are provided as a `.json` format as shown below. Documentation on backend extensions and configuraton parameters is available in the Qualcomm AI Engine Direct SDK Documents."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4bfc1206",
   "metadata": {},
   "outputs": [],
   "source": [
    "# HTP backend extensions config file (htp_backend_extensions.json) example\n",
    "htp_backend_extensions_data = '''\n",
    "{\n",
    "    \"backend_extensions\": {\n",
    "        \"shared_library_path\": \"libQnnHtpNetRunExtensions.so\",\n",
    "        \"config_file_path\": \"/tmp/htp_config.json\"\n",
    "    }\n",
    "}\n",
    "'''\n",
    "\n",
    "# HTP backend config file (htp_config.json) example\n",
    "htp_backend_config_data = '''\n",
    "{\n",
    "    \"graphs\": [{\n",
    "        \"vtcm_mb\":8,\n",
    "        \"graph_names\":[\"qnn_model\"]\n",
    "    }],\n",
    "    \"devices\": [\n",
    "        {\n",
    "            \"soc_id\": 57,\n",
    "            \"dsp_arch\": \"v73\",\n",
    "            \"cores\":[{\n",
    "                \"core_id\": 0,\n",
    "                \"perf_profile\": \"burst\",\n",
    "                \"rpc_control_latency\":100\n",
    "            }]\n",
    "        }\n",
    "    ]\n",
    "}\n",
    "'''\n",
    "#write the config files to a temporary location\n",
    "with open('/tmp/htp_backend_extensions.json','w') as f:\n",
    "    f.write(htp_backend_extensions_data)\n",
    "with open('/tmp/htp_config.json','w') as f:\n",
    "    f.write(htp_backend_config_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b9386a4a",
   "metadata": {
    "vscode": {
     "languageId": "shellscript"
    }
   },
   "outputs": [],
   "source": [
    "# Create a path under the models directory for serialized binaries\n",
    "!mkdir -p $STABLE_DIFFUSION_MODELS/serialized_binaries"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "73210cd5",
   "metadata": {},
   "source": [
    "### Generate the QNN context binary for text encoder "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "408e51b4",
   "metadata": {
    "vscode": {
     "languageId": "shellscript"
    }
   },
   "outputs": [],
   "source": [
    "proc = subprocess.Popen([QNN_SDK_ROOT + \"/bin/x86_64-linux-clang/qnn-context-binary-generator\",\n",
    "                             \"--model\", STABLE_DIFFUSION_MODELS + \"/converted_text_encoder/x86_64-linux-clang/libtext_encoder.so\",\n",
    "                             \"--backend\", \"libQnnHtp.so\",\n",
    "                             \"--output_dir\",  STABLE_DIFFUSION_MODELS + \"/serialized_binaries\",\n",
    "                             \"--binary_file\", \"text_encoder.serialized\",\n",
    "                             \"--config_file\", \"/tmp/htp_backend_extensions.json\",\n",
    "                             \"--log_level\", \"verbose\"\n",
    "                        ],stdout=subprocess.PIPE, stderr=subprocess.PIPE,env=env)\n",
    "output, error = proc.communicate()\n",
    "print(output.decode(),error.decode())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "27929b38",
   "metadata": {},
   "source": [
    "###  Generate the QNN context binary for U-Net\n",
    "Expected execution time: ~2 minutes\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3a7254d7",
   "metadata": {
    "vscode": {
     "languageId": "shellscript"
    }
   },
   "outputs": [],
   "source": [
    "proc = subprocess.Popen([QNN_SDK_ROOT + \"/bin/x86_64-linux-clang/qnn-context-binary-generator\",\n",
    "                             \"--model\", STABLE_DIFFUSION_MODELS + \"/converted_unet/x86_64-linux-clang/libunet.so\",\n",
    "                             \"--backend\", \"libQnnHtp.so\",\n",
    "                             \"--output_dir\",  STABLE_DIFFUSION_MODELS + \"/serialized_binaries\",\n",
    "                             \"--binary_file\", \"unet.serialized\",\n",
    "                             \"--config_file\", \"/tmp/htp_backend_extensions.json\"\n",
    "                        ],stdout=subprocess.PIPE, stderr=subprocess.PIPE,env=env)\n",
    "output, error = proc.communicate()\n",
    "print(output.decode(),error.decode())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4e986938",
   "metadata": {},
   "source": [
    "### Generate the QNN context binary for VAE Decoder\n",
    "Expected execution time: ~1.5 minutes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b7f4a5b0",
   "metadata": {
    "vscode": {
     "languageId": "shellscript"
    }
   },
   "outputs": [],
   "source": [
    "proc = subprocess.Popen([QNN_SDK_ROOT + \"/bin/x86_64-linux-clang/qnn-context-binary-generator\",\n",
    "                             \"--model\", STABLE_DIFFUSION_MODELS + \"/converted_vae_decoder/x86_64-linux-clang/libvae_decoder.so\",\n",
    "                             \"--backend\", \"libQnnHtp.so\",\n",
    "                             \"--output_dir\",  STABLE_DIFFUSION_MODELS + \"/serialized_binaries\",\n",
    "                             \"--binary_file\", \"vae_decoder.serialized\",\n",
    "                             \"--config_file\", \"/tmp/htp_backend_extensions.json\"\n",
    "                        ],stdout=subprocess.PIPE, stderr=subprocess.PIPE,env=env)\n",
    "output, error = proc.communicate()\n",
    "print(output.decode(),error.decode())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "green-syracuse",
   "metadata": {},
   "source": [
    "Upon completion of these steps to prepare Stable Diffusion models for inference, QNN context binaries for the three models are available in `$STABLE_DIFFUSION_MODELS/serialized_binaries/`\n",
    "\n",
    "The next step is to execute the prepared models (now represented as serialized context binaries) on a Snapdragon Gen2 Android device using executable utilities available in the Qualcomm AI Engine Direct SDK.\n",
    "\n",
    "\n",
    "Copyright (c) 2023 Qualcomm Technologies, Inc. and/or its subsidiaries."
   ]
  }
 ],
 "metadata": {
  "celltoolbar": "Edit Metadata",
  "kernelspec": {
   "display_name": "onnx",
   "language": "python",
   "name": "onnx"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
